import os

MODEL_CONFIG = {
    "base_url": "http://localhost:11434",
    "model": "llama3",
    "temperature": 0.8,
    "max_new_tokens": 512,
    "keep_alive": 500,
}


EMBEDDING_PATH = "data/processed/"
